{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf0f29ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3372b6-a61a-4701-a69f-4ae8152685cd",
      "metadata": {
        "id": "cf3372b6-a61a-4701-a69f-4ae8152685cd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a92fab",
      "metadata": {
        "id": "d0a92fab"
      },
      "source": [
        "Memory Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29118f6c",
      "metadata": {
        "id": "29118f6c"
      },
      "outputs": [],
      "source": [
        "def reduce_memo(df):\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype ==\"float64\":\n",
        "            df[col]=df[col].astype('float32')\n",
        "\n",
        "        elif df[col].dtype==('int64'):\n",
        "            df[col]=df[col].astype('int32')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c301c256",
      "metadata": {
        "id": "c301c256"
      },
      "source": [
        "LOAD THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6955551e",
      "metadata": {
        "id": "6955551e"
      },
      "outputs": [],
      "source": [
        "departments= pd.read_csv(\"D:\\DATASET\\departments.csv\")\n",
        "orders=pd.read_csv(\"D:\\DATASET\\orders.csv\")\n",
        "order_product=pd.read_csv(\"D:\\DATASET\\order_products__prior.csv\")\n",
        "product=pd.read_csv(\"D:\\DATASET\\products.csv\")\n",
        "aisle=pd.read_csv(\"D:\\DATASET/aisles.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8e9412",
      "metadata": {},
      "outputs": [],
      "source": [
        "orders= reduce_memo(orders)\n",
        "departments=reduce_memo(departments)\n",
        "order_product=reduce_memo(order_product)\n",
        "product=reduce_memo(product)\n",
        "aisle=reduce_memo(aisle)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4704d507",
      "metadata": {
        "id": "4704d507"
      },
      "source": [
        "Look at the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a49228c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0a49228c",
        "outputId": "8bbc1a94-8508-4270-96d1-49007b2ae224"
      },
      "outputs": [],
      "source": [
        "aisle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf5e433",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eaf5e433",
        "outputId": "b189011f-1ae3-491d-e7d3-cb6562bff377"
      },
      "outputs": [],
      "source": [
        "order_product.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60ec6eb1",
      "metadata": {
        "id": "60ec6eb1"
      },
      "source": [
        "We will join our data into one df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8dd754",
      "metadata": {
        "id": "ce8dd754"
      },
      "outputs": [],
      "source": [
        "complete_df=pd.merge(order_product,product,how='inner',on='product_id')\n",
        "complete_df=pd.merge(complete_df,departments,how='inner',on='department_id')\n",
        "complete_df=pd.merge(complete_df,aisle,how='inner',on='aisle_id')\n",
        "complete_df=pd.merge(complete_df,orders,how='inner',on='order_id')\n",
        "complete_df.head()\n",
        "sample_df=complete_df.sample(200000,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcfa79d0",
      "metadata": {
        "id": "dcfa79d0"
      },
      "source": [
        "EDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d53066",
      "metadata": {
        "id": "77d53066"
      },
      "source": [
        "Look at data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2188f8e9",
      "metadata": {
        "id": "2188f8e9"
      },
      "outputs": [],
      "source": [
        "complete_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca3249d7",
      "metadata": {
        "id": "ca3249d7"
      },
      "source": [
        "Summary of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5000b609",
      "metadata": {
        "id": "5000b609"
      },
      "outputs": [],
      "source": [
        "complete_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982b97e2",
      "metadata": {
        "id": "982b97e2"
      },
      "source": [
        "Distrubution of days since prior order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58cbf83",
      "metadata": {
        "id": "e58cbf83"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(complete_df['days_since_prior_order'],bins=30,kde=False)\n",
        "plt.title(\"Distrubution of days Since Prior Order\")\n",
        "plt.xlabel(\"Days Since Prior Order\")\n",
        "plt.ylabel(\"Count of Orders\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "168edd35",
      "metadata": {
        "id": "168edd35"
      },
      "source": [
        "Top 30 Product Orderd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb3b3fb",
      "metadata": {
        "id": "4fb3b3fb"
      },
      "outputs": [],
      "source": [
        "most_ordered=complete_df['product_name'].value_counts().head(30)\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=most_ordered,y=most_ordered.index)\n",
        "plt.xlabel(\"count of orders\")\n",
        "plt.title(\"Top 30 Product Ordred\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e6d9246",
      "metadata": {
        "id": "8e6d9246"
      },
      "source": [
        "Day Of Week Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f1d5236",
      "metadata": {
        "id": "1f1d5236"
      },
      "outputs": [],
      "source": [
        "sns.histplot(complete_df['order_dow'],bins=7,kde=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d69bc30",
      "metadata": {
        "id": "0d69bc30"
      },
      "source": [
        "Order Per department"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f0206c",
      "metadata": {
        "id": "e3f0206c"
      },
      "outputs": [],
      "source": [
        "top_departments=complete_df['department'].value_counts()\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_departments,y=top_departments.index)\n",
        "plt.xlabel(\"count of orders\")\n",
        "plt.title(\"ORDER PER DEPARTMENT\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b84302",
      "metadata": {
        "id": "44b84302"
      },
      "source": [
        "Number of orders per users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13c185d",
      "metadata": {
        "id": "c13c185d"
      },
      "outputs": [],
      "source": [
        "user_order=complete_df.groupby('user_id')['order_number'].max()\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(user_order,bins=30)\n",
        "plt.title(\"Number of Orders Per User\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83282f0",
      "metadata": {
        "id": "a83282f0"
      },
      "source": [
        "Reorderd Vs orderd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20300703",
      "metadata": {
        "id": "20300703"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "sns.countplot(x=complete_df['reordered'])\n",
        "plt.title(\"Reorderd vs Not Reorderd\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a02dd0a",
      "metadata": {
        "id": "6a02dd0a"
      },
      "source": [
        "The Top 20 aisle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc9e859",
      "metadata": {
        "id": "cbc9e859"
      },
      "outputs": [],
      "source": [
        "top_aisle=complete_df['aisle'].value_counts().head(20)\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_aisle,y=top_aisle.index)\n",
        "plt.title(\"Top 20 aisle\")\n",
        "plt.xlabel(\"count (Number of products)\")\n",
        "plt.ylabel(\"aisle\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac72d8f6",
      "metadata": {
        "id": "ac72d8f6"
      },
      "source": [
        "REorder VS Order number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05dee41f",
      "metadata": {
        "id": "05dee41f"
      },
      "outputs": [],
      "source": [
        "order_ordernum=complete_df.groupby('order_number')['reordered'].mean().reset_index()\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.lineplot(data=order_ordernum,x='order_number',y='reordered')\n",
        "plt.title(\"Reorder Rate VS Order Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf81fc3",
      "metadata": {
        "id": "dcf81fc3"
      },
      "source": [
        "Handle Numrical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a25d6b",
      "metadata": {
        "id": "70a25d6b"
      },
      "outputs": [],
      "source": [
        "num_cols=complete_df.select_dtypes(include=['int32','float32','int64','float64']).columns\n",
        "num_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2dde38",
      "metadata": {
        "id": "6e2dde38"
      },
      "source": [
        "Handle Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0539c107",
      "metadata": {
        "id": "0539c107"
      },
      "outputs": [],
      "source": [
        "cat_cols=complete_df.select_dtypes(include=['object']).columns\n",
        "cat_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41ada33c",
      "metadata": {
        "id": "41ada33c"
      },
      "source": [
        "Correlation For Numrical Featuers (\"Heatmap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a5bcd7",
      "metadata": {
        "id": "f5a5bcd7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "correlation_matrix=complete_df[num_cols].corr()\n",
        "sns.heatmap(correlation_matrix,annot=True,cmap='coolwarm')\n",
        "plt.title(\"Numerical Feature Correlation\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd835189",
      "metadata": {
        "id": "bd835189"
      },
      "source": [
        "Correlation For Numrical Featuers (\"pairwise scatter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf35bf30",
      "metadata": {
        "id": "cf35bf30"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,9))\n",
        "sample_df=complete_df.sample(1000,random_state=42)\n",
        "sns.pairplot(sample_df[num_cols])\n",
        "plt.title(\"Pairplot of Numerical Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a815805",
      "metadata": {
        "id": "8a815805"
      },
      "source": [
        "Time Of Day plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab563e7",
      "metadata": {
        "id": "eab563e7"
      },
      "outputs": [],
      "source": [
        "whole_day=complete_df['order_hour_of_day'].value_counts().sort_index()\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=whole_day.index,y=whole_day.values)\n",
        "plt.title(\"Orders by Hour of Day\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4762f3dc",
      "metadata": {
        "id": "4762f3dc"
      },
      "source": [
        "Orders in the Whole Week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1df9230",
      "metadata": {
        "id": "f1df9230"
      },
      "outputs": [],
      "source": [
        "whole_week=complete_df['order_dow'].value_counts().sort_index()\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=whole_week.index,y=whole_week.values)\n",
        "plt.title(\"Orders by Day of Week\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6377f33",
      "metadata": {
        "id": "e6377f33"
      },
      "outputs": [],
      "source": [
        "# --- IGNORE ---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73abfa0",
      "metadata": {
        "id": "a73abfa0"
      },
      "source": [
        "HANDLE MISSING VALUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99128f06",
      "metadata": {
        "id": "99128f06"
      },
      "outputs": [],
      "source": [
        "missing_value= complete_df.isnull().sum()\n",
        "missing_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1ef1220",
      "metadata": {
        "id": "f1ef1220"
      },
      "outputs": [],
      "source": [
        "missing_count=complete_df.isnull().sum()\n",
        "missing_count=missing_count[missing_count>0].sort_values(ascending=False)\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.barplot(x=missing_count.index,y=missing_count.values)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Missing Value Per Column\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac07440c",
      "metadata": {
        "id": "ac07440c"
      },
      "outputs": [],
      "source": [
        "print (\"..\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a087c740",
      "metadata": {
        "id": "a087c740"
      },
      "source": [
        "3. Cleaning & Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d0485f",
      "metadata": {
        "id": "f2d0485f"
      },
      "source": [
        "Median Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1623ea21",
      "metadata": {
        "id": "1623ea21"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "median_df=complete_df.copy()\n",
        "median_imputer=SimpleImputer(strategy='median')\n",
        "median_df['days_since_prior_order']=median_imputer.fit_transform(median_df[['days_since_prior_order']])\n",
        "median_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f37d1f21",
      "metadata": {
        "id": "f37d1f21"
      },
      "source": [
        " Median Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6abf66",
      "metadata": {
        "id": "4e6abf66"
      },
      "outputs": [],
      "source": [
        "median_df.isnull().sum()\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(median_df['days_since_prior_order'], bins=30, kde=False)\n",
        "plt.title(\"Histogram of Days Since Prior Order(Median Imputation)\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19ca10bb",
      "metadata": {
        "id": "19ca10bb"
      },
      "source": [
        "Most Frequent (Mode) Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95eb39f8",
      "metadata": {
        "id": "95eb39f8"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "freq_df=complete_df.copy()\n",
        "freq_imputer = SimpleImputer(strategy='most_frequent')\n",
        "freq_df['days_since_prior_order'] = freq_imputer.fit_transform(freq_df[['days_since_prior_order']])\n",
        "freq_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77557b42",
      "metadata": {
        "id": "77557b42"
      },
      "source": [
        "Most Frequent (Mode) Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bc89369",
      "metadata": {
        "id": "9bc89369"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(freq_df['days_since_prior_order'], bins=30, kde=False)\n",
        "plt.title(\"Histogram of Days Since Prior Order (Mode Imputation)\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d904136d",
      "metadata": {
        "id": "d904136d"
      },
      "source": [
        "Sentinel Imputation (الي رح نعتمده)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a01aa27c",
      "metadata": {
        "id": "a01aa27c"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "sentinel_df=complete_df.copy()\n",
        "sentinel_vl=0\n",
        "sentinel_df['days_since_prior_order']=sentinel_df['days_since_prior_order'].fillna(sentinel_vl)\n",
        "sentinel_df.isnull().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0425ff31",
      "metadata": {
        "id": "0425ff31"
      },
      "source": [
        "Sentinel Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8bfda2",
      "metadata": {
        "id": "cd8bfda2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(sentinel_df['days_since_prior_order'], bins=30, kde=False)\n",
        "plt.title(\"Histogram of Days Since Prior Order (Sentinel Value Imputation)\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7285eb5",
      "metadata": {
        "id": "b7285eb5"
      },
      "source": [
        "Model-Based Imputation (KNN Imputer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b61b79a",
      "metadata": {
        "id": "2b61b79a"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "sample_knn = complete_df.sample(100000, random_state=42)\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "knn_sample_df = sample_knn.copy()\n",
        "knn_sample_df[['days_since_prior_order']] = knn_imputer.fit_transform(knn_sample_df[['days_since_prior_order']])\n",
        "knn_sample_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75bc7af0",
      "metadata": {
        "id": "75bc7af0"
      },
      "source": [
        "Model Based Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce156a50",
      "metadata": {
        "id": "ce156a50"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(knn_sample_df['days_since_prior_order'], bins=30, kde=False)\n",
        "plt.title(\"Histogram of Days Since Prior Order (KNN Imputation)\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8450a8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "complete_df['days_since_prior_order']=complete_df['days_since_prior_order'].fillna(sentinel_vl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a768f2",
      "metadata": {
        "id": "98a768f2"
      },
      "source": [
        "3-Outlier Detection & Treatment (Z-Score Method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f41eaa",
      "metadata": {
        "id": "f4f41eaa"
      },
      "outputs": [],
      "source": [
        "outlier_columns = []\n",
        "for col in complete_df.select_dtypes(include=['int', 'float']):\n",
        "    Q1 = complete_df[col].quantile(0.25)\n",
        "    Q3 = complete_df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    if ((complete_df[col] < (Q1 - 1.5 * IQR)) | (complete_df[col] > (Q3 + 1.5 * IQR))).any():\n",
        "        outlier_columns.append(col)\n",
        "\n",
        "print(\"Outlier columns:\", outlier_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a7e7f0",
      "metadata": {
        "id": "e4a7e7f0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "outlier_columns=['add_to_cart_order','order_number']\n",
        "mean_val =complete_df[outlier_columns].mean()\n",
        "std_val  = complete_df[outlier_columns].std()\n",
        "z_score = (complete_df[outlier_columns]- mean_val) / std_val\n",
        "z_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40067988",
      "metadata": {
        "id": "40067988"
      },
      "source": [
        "\n",
        "Extracting Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d06623d",
      "metadata": {
        "id": "5d06623d"
      },
      "outputs": [],
      "source": [
        "outlier_z = z_score[(z_score > 3) | (z_score < -3)]\n",
        "print(outlier_z.shape)\n",
        "len(outlier_z)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34029f07",
      "metadata": {
        "id": "34029f07"
      },
      "source": [
        "Boxplot Before Removing Outliers (Z-score) Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8a6353",
      "metadata": {
        "id": "1c8a6353"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,4))\n",
        "sample_df=complete_df.sample(20000,random_state=42)\n",
        "sns.boxplot(data=sample_df[outlier_columns])\n",
        "plt.title(\"Boxplot Before Removing Outliers (Z-score)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a2a781",
      "metadata": {
        "id": "68a2a781"
      },
      "source": [
        "Histogram Before Removing Outliers (Z-score) Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00438834",
      "metadata": {
        "id": "00438834"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "sns.histplot(data=sample_df[outlier_columns], bins=30, kde=False,palette=\"coolwarm\")\n",
        "plt.title(\"Histogram Before Removing Outliers (Z-score)\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0368e222",
      "metadata": {
        "id": "0368e222"
      },
      "source": [
        "Removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d02d17c6",
      "metadata": {
        "id": "d02d17c6"
      },
      "outputs": [],
      "source": [
        "clean_z_df =sample_df[(z_score <= 3) & (z_score >= -3)]\n",
        "clean_z_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d704e507",
      "metadata": {
        "id": "d704e507"
      },
      "source": [
        "Boxplot After Removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fee0296c",
      "metadata": {
        "id": "fee0296c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "sns.boxplot(data=clean_z_df[outlier_columns])\n",
        "plt.title(\"Boxplot After Removing Outliers (Z-score)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52fc6a71",
      "metadata": {
        "id": "52fc6a71"
      },
      "source": [
        "Histogram After Removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6c5493",
      "metadata": {
        "id": "3c6c5493"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(data=clean_z_df[outlier_columns], bins=30, kde=False)\n",
        "plt.title(\"Histogram After Removing Outliers (Z-score)\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7db3a199",
      "metadata": {
        "id": "7db3a199"
      },
      "source": [
        "4-Encoding Categorical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc297b1f",
      "metadata": {
        "id": "bc297b1f"
      },
      "source": [
        "One-Hot Encoding (for low-cardinality categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d31640",
      "metadata": {
        "id": "e6d31640"
      },
      "outputs": [],
      "source": [
        "low_card= ['department', 'aisle']\n",
        "one_hot = pd.get_dummies(\n",
        "   complete_df,\n",
        "    columns=low_card,\n",
        "    drop_first=True,\n",
        "    sparse=True)\n",
        "\n",
        "one_hot.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7cad999",
      "metadata": {
        "id": "b7cad999"
      },
      "source": [
        "5. Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0aeaabb",
      "metadata": {
        "id": "f0aeaabb"
      },
      "source": [
        "Feature Scaling(\"StandardScaler\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74a6918",
      "metadata": {
        "id": "d74a6918"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "standard_df=complete_df.copy()\n",
        "scaler=StandardScaler()\n",
        "standard_df[num_cols]=scaler.fit_transform(complete_df[num_cols])\n",
        "standard_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c26de1",
      "metadata": {
        "id": "66c26de1"
      },
      "source": [
        "Feature Scaling(\"MinMaxScaler\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7992189d",
      "metadata": {
        "id": "7992189d"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "min_max_df=complete_df.copy()\n",
        "MMS=MinMaxScaler()\n",
        "min_max_df[num_cols]=MMS.fit_transform(complete_df[num_cols])\n",
        "min_max_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5773b19",
      "metadata": {
        "id": "d5773b19"
      },
      "source": [
        "6- Feature Enginnering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80fd2f09",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(complete_df , columns = complete_df.columns)\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85bc55ca",
      "metadata": {
        "id": "85bc55ca"
      },
      "source": [
        "-User Level Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aae2e565",
      "metadata": {},
      "outputs": [],
      "source": [
        "user_total_orders = df.groupby('user_id')['order_number'].max().reset_index()\n",
        "user_total_orders.columns = ['user_id', 'user_total_orders']#total_order\n",
        "user_total_orders=user_total_orders.sort_values(by='user_id').reset_index(drop=True)\n",
        "user_total_orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98375764",
      "metadata": {},
      "outputs": [],
      "source": [
        "basket_data = df.groupby('user_id').agg({ 'product_id':'count', 'order_number': 'max'}).reset_index()\n",
        "basket_data.columns = ['user_id', 'total_products_ordered', 'total_orders']\n",
        "basket_data['avg_basket_size'] = basket_data['total_products_ordered'] / basket_data['total_orders']#avg basket sizehحجم سلة المتوسط يلي كل مره بشتري فيها \n",
        "basket_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4ce21f",
      "metadata": {
        "id": "0d4ce21f"
      },
      "outputs": [],
      "source": [
        "user_features = df.groupby('user_id').agg({\n",
        "    'order_number': 'max',       \n",
        "     'product_id': 'count',       \n",
        "    'reordered': 'mean',         \n",
        "    'days_since_prior_order': ['mean', 'last'] \n",
        "}).reset_index()\n",
        "user_features.columns = ['user_id',  'user_total_orders',  'user_total_items', 'user_reorder_ratio','user_avg_days_between', 'user_days_since_last_order'  ]\n",
        "display(user_features.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9216c91a",
      "metadata": {},
      "outputs": [],
      "source": [
        "user_features = df.groupby('user_id').agg({\n",
        "    'order_number': 'max',       \n",
        "     'product_id': 'count',       \n",
        "    'reordered': 'mean',         \n",
        "    'days_since_prior_order': ['mean', 'last'] \n",
        "}).reset_index()\n",
        "user_features.columns = ['user_id',  'user_total_orders',  'total_products_ordered', 'user_reorder_ratio','user_avg_days_between', 'user_days_since_last_order'  ]\n",
        "user_features['user_avg_basket_size'] = user_features[  'total_products_ordered'] / user_features['user_total_orders'] #size of basket\n",
        "display(user_features.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddfcf065",
      "metadata": {
        "id": "ddfcf065"
      },
      "source": [
        "- Product-level features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974aaf87",
      "metadata": {
        "id": "974aaf87"
      },
      "outputs": [],
      "source": [
        "product_features = df.groupby('product_id').agg({ \n",
        "        'reordered': 'mean', \n",
        "        'add_to_cart_order': 'mean',   \n",
        "        'user_id': 'count'   #Popularity\n",
        "}).reset_index()\n",
        "product_features.columns = [ 'product_id' ,'product_reorder_rate', 'product_avg_cart_position', 'product_total_purchases']\n",
        "display(product_features.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1d29cf",
      "metadata": {
        "id": "4b1d29cf"
      },
      "source": [
        "User×Product interaction features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca9e9646",
      "metadata": {
        "id": "ca9e9646"
      },
      "outputs": [],
      "source": [
        "\n",
        "uxp_features = df.groupby(['user_id', 'product_id']).agg({\n",
        "    'reordered': ['count', 'mean'], #prior purchase count& reorder probability عدد لمشتريات السابقة \n",
        "    'order_number': 'max'#last order\n",
        "}).reset_index()  \n",
        "uxp_features.columns = [\n",
        "    'user_id', \n",
        "    'product_id', \n",
        "    'uxp_total_bought',       # كم مرة اشترى المنتج\n",
        "    'uxp_reorder_ratio',      # نسبة إعادة الطلب\n",
        "    'uxp_last_order_num'      # رقم آخر طلب اشترى فيه المنتج (عشان نحسب Recency بعدين)\n",
        "]\n",
        "\n",
        "display(uxp_features.head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c538583e",
      "metadata": {
        "id": "c538583e"
      },
      "source": [
        "Temporal features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f7b1cb7",
      "metadata": {
        "id": "9f7b1cb7"
      },
      "outputs": [],
      "source": [
        "df['order_hour']=df['order_hour_of_day']#Hour\n",
        "\n",
        "df['order_day']=df['order_dow']#Day\n",
        "\n",
        "start_year=2024\n",
        "days_per_year=365\n",
        "df['order_year'] = start_year + df['days_since_prior_order']//days_per_year #Year\n",
        "df['order_month'] = ((df['days_since_prior_order'] % days_per_year) // 30) + 1 #Month\n",
        "\n",
        "def get_season(month):\n",
        "    if month in [3, 4, 5]:\n",
        "        return 'Spring'\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 'Summer'\n",
        "    elif month in [9, 10, 11]:\n",
        "        return 'Fall'\n",
        "    else:\n",
        "        return 'Winter'\n",
        "df['order_season'] = df['order_month'].apply(get_season)#Season\n",
        "\n",
        "df['is_weekend'] = df['order_dow'].apply(lambda x: 1 if x in [0, 1] else 0)#Holiday\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca81c6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "                                                                                              #جزء من temporal features ممكن انه نعملها \n",
        "\n",
        "def time_of_day(hour):\n",
        "    if 6 <= hour < 11:                                                                        # بحيث انه اقسم الوقت صبح ومسا وهيك\n",
        "        return 'Morning'\n",
        "    elif 12 <= hour < 17:\n",
        "        return 'Afternoon'\n",
        "    elif 18 <= hour < 23:\n",
        "        return 'Evening'\n",
        "   \n",
        "    else:\n",
        "        return 'Night'\n",
        "df['time_of_day'] = df['order_hour_of_day'].apply(time_of_day)\n",
        "print(df['time_of_day'].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e92912",
      "metadata": {},
      "source": [
        "Aggregations over windows (e.g., last 3 orders, last 6 months)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kjEI9_nuzpBe",
      "metadata": {
        "id": "kjEI9_nuzpBe"
      },
      "outputs": [],
      "source": [
        "\n",
        "order_metrics = df.groupby(['user_id', 'order_number']).agg({\n",
        "    'product_id': 'count',            # حجم السلة (كم حبة اشترى بالطلب)\n",
        "    'days_since_prior_order': 'max'   # كم يوم غاب قبل هاد الطلب\n",
        "}).reset_index()\n",
        "\n",
        "order_metrics.rename(columns={\n",
        "    'product_id': 'basket_size',\n",
        "    'days_since_prior_order': 'days_gap'\n",
        "}, inplace=True)\n",
        "\n",
        "# لازم نرتب تصاعدي عشان لما نقول \"آخر 3\" يكونوا عنجد آخر 3\n",
        "order_metrics = order_metrics.sort_values(['user_id', 'order_number'])\n",
        "\n",
        "def get_recent_avg(x):\n",
        "    return x.rolling(window=3, min_periods=1).mean()\n",
        "\n",
        "order_metrics['avg_basket_last_3'] = order_metrics.groupby('user_id')['basket_size'].transform(get_recent_avg)#متوسط عدد المنتجات ل اخر 3 طلبات\n",
        "\n",
        "\n",
        "order_metrics['avg_days_gap_last_3'] = order_metrics.groupby('user_id')['days_gap'].transform(get_recent_avg) #المتوسط الزمني بين الطلبات الثلاث الاخيرة \n",
        "\n",
        "user_rolling_features = order_metrics.groupby('user_id').last().reset_index() #احدث حالة لكل مستخدم \n",
        "\n",
        "user_rolling_features = user_rolling_features[['user_id', 'avg_basket_last_3', 'avg_days_gap_last_3']]\n",
        "\n",
        "\n",
        "display(user_rolling_features.head(10))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "805fcbca",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = df.copy()\n",
        "train_df = train_df.merge(user_features , on = 'user_id' , how = 'left')\n",
        "train_df = train_df.drop(columns=[col for col in user_features.columns if col in train_df.columns and col != 'user_id']) #تجنب التكرار\n",
        "train_df = train_df.merge(user_features , on = 'user_id', how = 'left')\n",
        "train_df = train_df.merge(product_features , on = 'product_id', how = 'left')\n",
        "train_df = train_df.merge(uxp_features , on = ['user_id' , 'product_id'] , how = 'left')\n",
        "train_df = train_df.merge(user_rolling_features , on = 'user_id' , how = 'left')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441258c1",
      "metadata": {},
      "source": [
        "At least one engineered non-linear feature (log transforms, polynomial, interaction\n",
        "terms).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdb453c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['log_days_gap'] = np.log1p(df['days_since_prior_order'])\n",
        "df[['days_since_prior_order', 'log_days_gap']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k5tT3jB1yAn2",
      "metadata": {
        "id": "k5tT3jB1yAn2"
      },
      "source": [
        "Dimensionality & collinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pGBTjzgG4QIw",
      "metadata": {
        "id": "pGBTjzgG4QIw"
      },
      "outputs": [],
      "source": [
        "cols_for_corr = [\n",
        "    'reordered', \n",
        "    'add_to_cart_order', \n",
        "    'order_number', \n",
        "    'order_dow', \n",
        "    'order_hour_of_day', \n",
        "    'days_since_prior_order'\n",
        "]\n",
        "\n",
        "sample_corr = complete_df[cols_for_corr].corr()\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(sample_corr, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Numerical Feature Correlation (Sampled Data)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81380b6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "id_cols = ['order_id' , 'user_id' , 'product_id' , 'aisle_id' , 'department_id']\n",
        "low_cols = [\"department_id\" , \"order_dow\" , \"time_of_day\"] \n",
        "high_cols = [\"user_id\" , \"product_id\" , \"aisle_id\"] \n",
        "\n",
        "train_df[high_cols] = train_df[high_cols].astype(str)\n",
        "#عشان التارقيت ما بشتغل غير مع كاتيقوري\n",
        "target_col = \"reordered\"\n",
        "Frequency_col = \"product_name\"\n",
        "\n",
        "#عدد الاعمده كبير جدا فقلت بعمل لوب + استثناءات عشان اريح راسي\n",
        "num_cols = (train_df.drop(columns=[target_col]).select_dtypes(include=[\"int32\" , \"float32\"]).columns.tolist())\n",
        "num_cols = [c for c in num_cols if c not in id_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "snqaEgJW7zVg",
      "metadata": {
        "id": "snqaEgJW7zVg"
      },
      "source": [
        "VIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e_jygYUr8aEz",
      "metadata": {
        "id": "e_jygYUr8aEz"
      },
      "outputs": [],
      "source": [
        "reduce_memo(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c740ef63",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59SDMaKm_fXK",
      "metadata": {
        "id": "59SDMaKm_fXK"
      },
      "outputs": [],
      "source": [
        "%pip install statsmodels\n",
        "#بدي استخدم VIF , هاض عباره عن فنكشن رياضي ببين قديش في ارتباط وتكرار بين الاعمده نفسهم \n",
        "#الهدف منه اني اشوف شو في اعمده فيهم تشابه كبير وبقدمو نفس المعلومه تقريبا عشان احذف واحد منهم\n",
        "#بدي استخدم VIF , هاض عباره عن فنكشن رياضي ببين قديش في ارتباط وتكرار بين الاعمده نفسهم \n",
        "#الهدف منه اني اشوف شو في اعمده فيهم تشابه كبير وبقدمو نفس المعلومه تقريبا عشان احذف واحد منهم\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "SAMPLE_SIZE = 50000 \n",
        "V = train_df[num_cols].sample(n=SAMPLE_SIZE , random_state = 42)\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif[\"feature\"] = V[num_cols].columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(V.values , i) for i in range(V.shape[1])]\n",
        "\n",
        "#تحت 5 ممتاز\n",
        "#بين ال 6 وال 10 مقبول\n",
        "#اكثر من هيك بدك تشوف شو و وين في ترابط غير مهم وتبلش تحذف\n",
        "#ال inf حذف مباشره\n",
        "\n",
        "vif.sort_values(\"VIF\" , ascending = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da16fa64",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize = (8 , 5))\n",
        "plt.scatter(vif[\"VIF\"] , vif[\"feature\"])\n",
        "plt.axvline(10 , color = 'red' , linestyle = '--')\n",
        "plt.xlabel(\"VIF\")\n",
        "plt.title(\"VIF Scatter Plot\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80cbf4cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "#حذفت القيم اللانهائيه , والقيم اللي فيها النسبه عاليه , لانهم بدلو على تكرار وتشابه المعلومات , يعني لو خليتهم كلهم زي كأني مكرر نفس العامود ما فرقت \n",
        "drop_cols = [\n",
        "    \n",
        "    \"uxp_days_last_order_\" ,\n",
        "    #u_total_orders_log كنت بدي اخليه بما انه تعبنا عليه بمرحلة الهندسه بس النسبه فيه كانت كثير عاليه :(\n",
        "    \"user_total_orders\" ,\n",
        "\n",
        "    \"product_avg_cart_position\" ,\n",
        "    \"product_reorder_rate\" ,\n",
        "    \"user_reorder_ratio\" \n",
        "    ]\n",
        "\n",
        "train_df = train_df.drop(columns = drop_cols , errors=\"ignore\")\n",
        "\n",
        "#صار عندي ايرور بالبريبروسيسر لانه الداتا صار فيها عدم تطابق بعد الدروب ف بدي ارجع انسخ الاعمده كمان مره\n",
        "num_cols = (train_df.drop(columns=[target_col]).select_dtypes(include=[\"int32\" , \"float32\"]).columns.tolist())\n",
        "num_cols = [c for c in num_cols if c not in id_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6590c04",
      "metadata": {},
      "source": [
        "Embalanced Data Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69041ed4",
      "metadata": {},
      "outputs": [],
      "source": [
        "orders_train = pd.read_csv(r\"C:\\Users\\Acer Nitro\\Downloads\\order_products__train.csv\\order_products__train.csv\")\n",
        "orders_train = orders_train[['order_id', 'product_id', 'reordered']]\n",
        "\n",
        "train_df['reordered_y']=orders_train['reordered']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a28c01",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['reordered_y'].value_counts()\n",
        "train_df['reordered_y'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2ed0966",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['reordered_y'].isnull().sum()\n",
        "train_df['reordered_y'] = train_df['reordered_y'].fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c46285a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "train_df['reordered'].value_counts().plot(\n",
        "    kind='bar', ax=axes[0], title='reordered'\n",
        ")\n",
        "\n",
        "train_df['reordered_y'].value_counts().plot(\n",
        "    kind='bar', ax=axes[1], title='reordered_y'\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe54369",
      "metadata": {},
      "source": [
        "هيك بنكون بيننا انو اصلا في عنا imbalanced بالداتا"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702801af",
      "metadata": {},
      "outputs": [],
      "source": [
        "reduce_memo(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa16589",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df=train_df.drop('reordered_y',axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3898a48d",
      "metadata": {},
      "source": [
        "TO SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8ed726",
      "metadata": {},
      "outputs": [],
      "source": [
        "id_cols = ['order_id', 'user_id', 'product_id', 'aisle_id', 'department_id']\n",
        "low_cols_ = [\"department\", \"order_dow\" , \"time_of_day\", \"aisle\", \"order_season\"] \n",
        "high_cols = [\"user_id\", \"product_id\", \"aisle_id\"] \n",
        "\n",
        "df[high_cols] = df[high_cols].astype(str)\n",
        "# عشان التارقيت ما بوخذ غير category\n",
        "\n",
        "target_col = \"reordered_y\"\n",
        "Frequency_col = \"product_name\"\n",
        "num_cols_ = [\n",
        "    \n",
        "    'user_avg_basket',\n",
        "    'user_reorder_ratio',\n",
        "    'user_last_order_recency',\n",
        "    'product_popularity',\n",
        "    'user_prod_purchase_count'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f95259e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure category_encoders is installed in the current kernel (try both PyPI names to be robust)\n",
        "%pip install --quiet category_encoders\n",
        "\n",
        "\n",
        "# import after installation\n",
        "import category_encoders as ce\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Frequency_col is a single column name string — pass as a list to ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"onehot\",\n",
        "         OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True, drop=\"first\"),\n",
        "         low_cols),\n",
        "\n",
        "        (\"target\",\n",
        "         ce.TargetEncoder(min_samples_leaf=20, smoothing=50),\n",
        "         high_cols),\n",
        "\n",
        "        (\"freq\",\n",
        "         ce.CountEncoder(normalize=True),\n",
        "         [Frequency_col]),\n",
        "\n",
        "        (\"scale\",\n",
        "         StandardScaler(),\n",
        "         num_cols)\n",
        "    ],\n",
        "    remainder=\"passthrough\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4268ef1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn\n",
        "!pip install xgboost\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline #  استدعينا بايبلاين خاص\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 1. تعريف الـ SMOTE\n",
        "# sampling_strategy=0.5 معناها: خلي عدد الـ 1 يصير نص عدد الـ 0 (نسبة 1:2)\n",
        "# هيك بنحسن التوازن بدون ما نغرق الداتا ببيانات صناعية\n",
        "smote = SMOTE(random_state=42, sampling_strategy=0.5)\n",
        "\n",
        "# 2. تعريف الموديل\n",
        "# ملاحظة مهمة: شلنا scale_pos_weight أو خليناه 1\n",
        "# ليش؟ لأن SMOTE أصلاً حل مشكلة الـ Imbalance، فما في داعي نعاقب الموديل مرتين!\n",
        "clf = XGBClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    scale_pos_weight=1,  # رجعناه للطبيعي\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    eval_metric='auc'\n",
        ")\n",
        "\n",
        "# 3. بناء البايبلاين الجديد (ImbPipeline)\n",
        "# الترتيب: معالجة -> SMOTE -> موديل\n",
        "model_pipeline = ImbPipeline(steps=[\n",
        "    ('preprocessor', preprocessor), # معالجتك القديمة\n",
        "    ('smote', smote),               # خطوة التوليد (بتصير بس عالـ Train)\n",
        "    ('model', clf)                  # التدريب\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283263ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import KFold\n",
        "target_users_count = 10000 \n",
        "\n",
        "unique_users = train_df['user_id'].unique()\n",
        "\n",
        "if target_users_count > len(unique_users):\n",
        "    target_users_count = len(unique_users)\n",
        "\n",
        "np.random.seed(42)\n",
        "my_users = np.random.choice(unique_users , size=target_users_count , replace=False)\n",
        "\n",
        "final_sample = train_df[train_df['user_id'].isin(my_users)].copy()\n",
        "\n",
        "final_sample = final_sample.sort_values(by=[\"user_id\", \"order_number\"])\n",
        "final_sample[\"last__orders\"] = final_sample[\"order_number\"] == final_sample.groupby(\"user_id\")[\"order_number\"].transform(\"max\")\n",
        "\n",
        "train_df_ = final_sample[final_sample['last__orders'] == False]\n",
        "test_df_ = final_sample[final_sample['last__orders'] == True]\n",
        "\n",
        "not_for_X_columns = ['reordered' , 'eval_set' , 'last__orders' ,  'order_id' , 'add_to_cart_order' , 'order_number',  'aisle' , 'department','time_of_day','uxp_last_order_num'] \n",
        "\n",
        "xc_train = train_df_.drop(columns=not_for_X_columns , errors='ignore')\n",
        "yc_train = train_df_['reordered']\n",
        "\n",
        "xc_test = test_df_.drop(columns = not_for_X_columns , errors = 'ignore')\n",
        "yc_test = test_df_['reordered']\n",
        "\n",
        "real_num_cols = [c for c in num_cols if c not in not_for_X_columns]\n",
        "real_low_cols = [c for c in low_cols if c not in not_for_X_columns]\n",
        "real_high_cols = [c for c in high_cols if c not in not_for_X_columns]\n",
        "\n",
        "# مدامني قسمت الداتا حسب الزمن فهيك عالاغلب مش رح احتاجه\n",
        "KF = KFold(n_splits = 5 , shuffle = True , random_state = 42)\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"encoding\" , OneHotEncoder(handle_unknown = \"ignore\" , sparse_output = True , drop = \"first\") , real_low_cols) ,\n",
        "\n",
        "        # Target Encoding يُستخدم مع الأعمدة الفئوية ذات عدد القيم الكبير.\n",
        "        # يتم تحويل كل فئة إلى متوسط قيمة المتغير الهدف المرتبط بها.\n",
        "        # لتجنب تسريب الهدف (Target Leakage)، يتم تطبيق الترميز داخل\n",
        "        # الـ Cross-Validation بحيث يُحسب الترميز من بيانات التدريب فقط.\n",
        "        # معاملات min_samples_leaf و smoothing تقلل تأثير الفئات النادرة\n",
        "        # عبر تقريبها من المتوسط العام، مما يحد من الـ overfitting.\n",
        "        (\"target_encoding\" , ce.TargetEncoder(min_samples_leaf = 20 , smoothing = 50) , real_high_cols) ,\n",
        "        (\"Frequency\" , ce.CountEncoder(normalize = True) , Frequency_col) ,\n",
        "        (\"scaling\" , StandardScaler() , real_num_cols)\n",
        "                 ]\n",
        ")\n",
        "\n",
        "# normlize =True -> عشان يخليلي كل القيم بين 0 و 1\n",
        "\n",
        "train_cls = preprocessor.fit_transform(xc_train , yc_train)\n",
        "test_cls = preprocessor.transform(xc_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ada1e9b",
      "metadata": {},
      "source": [
        "Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b51c375",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "np.random.seed(42)\n",
        "tuning_x = xc_train.copy()\n",
        "tuning_y = yc_train.copy()\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "gkf = GroupKFold(n_splits=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd8e1dc",
      "metadata": {},
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d2b6fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "KNNsmall_users = np.random.choice(tuning_x['user_id'].unique() , size = 2000 , replace = False)\n",
        "\n",
        "knn_x_small = tuning_x[tuning_x['user_id'].isin(KNNsmall_users)].copy()\n",
        "knn_y_small = tuning_y[tuning_x['user_id'].isin(KNNsmall_users)]\n",
        "\n",
        "\n",
        "\n",
        "KNN_pipline = make_pipeline(\n",
        "    preprocessor ,\n",
        "    KNeighborsClassifier(n_jobs = -1)\n",
        ")\n",
        "\n",
        "KNNparam_grid = {\n",
        "    \"kneighborsclassifier__n_neighbors\": [7 , 10 , 30,60,80,150] ,\n",
        "    \"kneighborsclassifier__weights\" : ['distance' , 'uniform']\n",
        "}\n",
        "\n",
        "KNN_grid_search = GridSearchCV(\n",
        "    estimator = KNN_pipline ,\n",
        "    param_grid = KNNparam_grid ,\n",
        "    cv = gkf ,\n",
        "    scoring = \"f1\" ,\n",
        "    n_jobs = -1\n",
        ")\n",
        "\n",
        "KNN_grid_search.fit(\n",
        "    knn_x_small,\n",
        "    knn_y_small,\n",
        "    groups=knn_x_small['user_id']\n",
        ")\n",
        "\n",
        "print(\"\\nBest Score:\", KNN_grid_search.best_score_)\n",
        "print(\"Best Parameters:\", KNN_grid_search.best_params_)\n",
        "'''with k =60 and weights = uniform got best score of 0.87'''\n",
        "'''with k =30 and weights = uniform got best score of 0.8974819271262918'''\n",
        "'''with k =7 and weights = distance got best score of 0.9720661157'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86916930",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_w = KNN_grid_search.best_params_['kneighborsclassifier__weights']\n",
        "best_k = KNN_grid_search.best_params_['kneighborsclassifier__n_neighbors']\n",
        "\n",
        "finalKNN_pip = make_pipeline(\n",
        "        preprocessor , \n",
        "        KNeighborsClassifier(n_neighbors = best_k , weights = 'uniform' , n_jobs = -1, metric='manhattan', )\n",
        ")\n",
        "\n",
        "finalKNN_pip.fit(xc_train, yc_train)\n",
        "\n",
        "\n",
        "y_pred_KNN = finalKNN_pip.predict(xc_test)\n",
        "\n",
        "print(classification_report(yc_test , y_pred_KNN))\n",
        "print('KNN Accuracy',accuracy_score(yc_test , y_pred_KNN))\n",
        "\n",
        "'''With Best Parameters k=30 , metric=distance : 0.9433722102'''\n",
        "''' With Tuning and change metric and wights : 0.8974819271262918 '''\n",
        "'''When i increase k over 30 the accuracy increases'''\n",
        "'''k=80 got accuracy of 0.9123456790123457 > k=30 '''\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "189a3491",
      "metadata": {},
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ac331e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "tuning_users = np.random.choice(tuning_x[\"user_id\"].unique(), size=2500, replace=False) \n",
        "\n",
        "# تجهيز عينة التونينق\n",
        "LoR_x_small = tuning_x[tuning_x['user_id'].isin(tuning_users)].copy().sort_values(by=['user_id'])\n",
        "LoR_y_small = tuning_y.loc[LoR_x_small.index]\n",
        "\n",
        "LoR_pipline = make_pipeline(\n",
        "    preprocessor , \n",
        "    LogisticRegression(solver = 'liblinear' , class_weight = 'balanced' , random_state = 42 , n_jobs = -1)\n",
        ")\n",
        "\n",
        "LoRparam_grid = {\n",
        "    \"logisticregression__C\": [0.001 , 0.01 , 0.1 , 1 , 10] ,\n",
        "    \"logisticregression__penalty\": ['l1' , 'l2']\n",
        "}\n",
        "\n",
        "LoR_grid_search = GridSearchCV(\n",
        "    estimator = LoR_pipline ,\n",
        "    param_grid = LoRparam_grid ,\n",
        "    cv = gkf ,\n",
        "    scoring = \"f1\" ,\n",
        "    n_jobs = -1\n",
        ")\n",
        "\n",
        "LoR_grid_search.fit(LoR_x_small , LoR_y_small, groups=LoR_x_small['user_id'])\n",
        "\n",
        "print(\"\\nBest Score:\", LoR_grid_search.best_score_)\n",
        "print(\"Best Parameters:\", LoR_grid_search.best_params_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3830276a",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_C = LoR_grid_search.best_params_[\"logisticregression__C\"]\n",
        "best_P = LoR_grid_search.best_params_[\"logisticregression__penalty\"]\n",
        "\n",
        "final_LoR_pipeline = make_pipeline(\n",
        "    preprocessor , \n",
        "    LogisticRegression(solver = 'liblinear' , C = best_C , penalty = best_P , class_weight = 'balanced' , random_state = 42 , n_jobs = -1)\n",
        ")\n",
        "\n",
        "final_LoR_pipeline.fit(xc_train, yc_train)\n",
        "\n",
        "y_pred_LoR = final_LoR_pipeline.predict(xc_test)\n",
        "\n",
        "print(classification_report(yc_test, y_pred_LoR))\n",
        "print(f\"Logistic Accuracy: {accuracy_score(yc_test , y_pred_LoR):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc62bcff",
      "metadata": {},
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf6703c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "tuning_users = np.random.choice(tuning_x[\"user_id\"].unique(), size=800, replace=False)\n",
        "RF_x_small = tuning_x[tuning_x['user_id'].isin(tuning_users)].copy().sort_values(by=['user_id'])\n",
        "RF_y_small = tuning_y.loc[RF_x_small.index]\n",
        "\n",
        "RF_pipline = make_pipeline(\n",
        "    preprocessor ,\n",
        "    RandomForestClassifier(class_weight = \"balanced\" , random_state = 42 , n_jobs = -1)\n",
        ")\n",
        "\n",
        "RFparam_grid = {\n",
        "    \"randomforestclassifier__n_estimators\": [100 , 150 , 200] , \n",
        "    \"randomforestclassifier__max_depth\": [None , 10 , 20] , \n",
        "    \"randomforestclassifier__min_samples_split\": [2 , 5 , 10] ,\n",
        "    \"randomforestclassifier__min_samples_leaf\": [1 , 2 , 4] ,\n",
        "    \"randomforestclassifier__class_weight\": ['balanced' , 'balanced_subsample']\n",
        "}\n",
        "\n",
        "RF_grid_search = GridSearchCV(\n",
        "    estimator = RF_pipline ,\n",
        "    param_grid = RFparam_grid , \n",
        "    cv =gkf,\n",
        "    scoring = \"f1\" ,\n",
        "    n_jobs = -1\n",
        ")\n",
        "\n",
        "RF_grid_search.fit(RF_x_small , RF_y_small,groups=RF_x_small['user_id'])\n",
        "\n",
        "print(\"\\nBest Score:\", RF_grid_search.best_score_)\n",
        "print(\"Best Parameters:\", RF_grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee2e7856",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_N = RF_grid_search.best_params_[\"randomforestclassifier__n_estimators\"]\n",
        "best_MD = RF_grid_search.best_params_[\"randomforestclassifier__max_depth\"]\n",
        "best_MSP = RF_grid_search.best_params_[ \"randomforestclassifier__min_samples_split\"]\n",
        "best_MSL = RF_grid_search.best_params_[\"randomforestclassifier__min_samples_leaf\"]\n",
        "best_W = RF_grid_search.best_params_[\"randomforestclassifier__class_weight\"]\n",
        "\n",
        "final_RF_pipeline = make_pipeline(\n",
        "    preprocessor,\n",
        "    RandomForestClassifier(n_estimators = best_N , max_depth = best_MD , \n",
        "                    min_samples_leaf = best_MSL , min_samples_split = best_MSP , \n",
        "                 class_weight = best_W , n_jobs = -1 , random_state = 42 \n",
        "                        )       \n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "final_RF_pipeline.fit(xc_train , yc_train)\n",
        "\n",
        "y_pred_RF = final_RF_pipeline.predict(xc_test)\n",
        "\n",
        "print(classification_report(yc_test, y_pred_RF))\n",
        "print(f\"Random Forest Accuracy: {accuracy_score(yc_test, y_pred_RF):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9583068b",
      "metadata": {},
      "source": [
        "Support Vector Machine "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f69df80d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV, GroupKFold\n",
        "import numpy as np\n",
        "svm_users = np.random.choice(\n",
        "    xc_train['user_id'].unique(),\n",
        "    size=1000,\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "svm_x_small = xc_train[xc_train['user_id'].isin(svm_users)].copy()\n",
        "svm_y_small = yc_train[xc_train['user_id'].isin(svm_users)]\n",
        "\n",
        "svm_pipeline = make_pipeline(\n",
        "    preprocessor,\n",
        "    SVC(probability=True, random_state=42)\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, GroupKFold\n",
        "import numpy as np\n",
        "\n",
        "param_dist = {\n",
        "    \"svc__C\": np.logspace(-2, 2, 6),\n",
        "    \"svc__kernel\": [\"rbf\", \"linear\"],\n",
        "    \"svc__gamma\": [\"scale\", \"auto\"]\n",
        "}\n",
        "\n",
        "gkf = GroupKFold(n_splits=3)\n",
        "\n",
        "svm_random = RandomizedSearchCV(\n",
        "    estimator=svm_pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=6,\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=gkf,\n",
        "    n_jobs=1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "svm_random.fit(\n",
        "    svm_x_small,\n",
        "    svm_y_small,\n",
        "    groups=svm_x_small['user_id']\n",
        ")\n",
        "\n",
        "print('Best Score :',svm_random.best_score_)\n",
        "print('Best Parameters :',svm_random.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d401dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_svm = svm_random.best_estimator_\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "\n",
        "y_pred_svm = best_svm.predict(xc_test)\n",
        "y_prob_svm = best_svm.predict_proba(xc_test)[:, 1]\n",
        "\n",
        "accuracy_score(yc_test, y_pred_svm)\n",
        "roc_auc_score(yc_test, y_prob_svm)\n",
        "print(classification_report(yc_test, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38d0cc4a",
      "metadata": {},
      "source": [
        "Linear SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2455bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_features = [\n",
        "    'order_dow',\n",
        "    'order_hour_of_day',\n",
        "    'days_since_prior_order',\n",
        "    'is_weekend',\n",
        "    'order_month',\n",
        "    'user_total_items',\n",
        "    'user_avg_days_between',\n",
        "    'user_days_since_last_order',\n",
        "    'product_total_purchases',\n",
        "    'uxp_total_bought',\n",
        "    'uxp_reorder_ratio',\n",
        "    'avg_basket_last_3',\n",
        "    'avg_days_gap_last_3'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2558e0e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "svm_users = np.random.choice(\n",
        "    xc_train['user_id'].unique(),\n",
        "    size=5000,\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "svm_x_small = xc_train[xc_train['user_id'].isin(svm_users)][dt_features].copy()\n",
        "svm_y_small = yc_train[xc_train['user_id'].isin(svm_users)]\n",
        "\n",
        "svm_sample_pipeline = make_pipeline(\n",
        "    CalibratedClassifierCV(\n",
        "        LinearSVC(\n",
        "            C=10,\n",
        "            max_iter=5000,\n",
        "            class_weight=\"balanced\",\n",
        "            random_state=42\n",
        "        ),\n",
        "        method=\"sigmoid\"\n",
        "    )\n",
        ")\n",
        "svm_sample_pipeline.fit(svm_x_small, svm_y_small)\n",
        "print(\"SVM with Linear Kernel Accuracy:\", accuracy_score(svm_y_small, svm_sample_pipeline.predict(svm_x_small)))\n",
        "print(classification_report(svm_y_small, svm_sample_pipeline.predict(svm_x_small)))\n",
        "\n",
        "'''SVM Score with Linear Kernel Accuracy: 0.809161776248863 -> with c= 1.0'''\n",
        "'''SVM Score with Linear Kernel Accuracy: 0.7996820567076329 -> with c= 10'''\n",
        "'''SVM Score with Linear Kernel Accuracy: 0.8020444783838858 -> with c= 0.1'''\n",
        "'''SVM Score with Linear Kernel Accuracy: 0.7984317144654071 with c=100'''\n",
        "\n",
        "'''The best Score C is 1.0 as it gives the highest accuracy of 0.8091'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c499a102",
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_features = [\n",
        "    'order_dow',\n",
        "    'order_hour_of_day',\n",
        "    'days_since_prior_order',\n",
        "    'is_weekend',\n",
        "    'order_month',\n",
        "    'user_total_items',\n",
        "    'user_avg_days_between',\n",
        "    'user_days_since_last_order',\n",
        "    'product_total_purchases',\n",
        "    'uxp_total_bought',\n",
        "    'uxp_reorder_ratio',\n",
        "    'avg_basket_last_3',\n",
        "    'avg_days_gap_last_3'\n",
        "]\n",
        "\n",
        "\n",
        "x_test_svm = xc_test[dt_features]\n",
        "\n",
        "y_pred_svm = svm_sample_pipeline.predict(x_test_svm)\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_score(yc_test, y_pred_svm))\n",
        "print(classification_report(yc_test, y_pred_svm))\n",
        "print (f\"SVM Accuracy: {accuracy_score(yc_test , y_pred_svm):.4f}\")\n",
        "'''SVM Accuracy 0.7327 With C=1.0'''\n",
        "'''SVM Accuracy 0.7273 With C=10'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af1d962",
      "metadata": {},
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ba9172",
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_features = [\n",
        "    'order_dow',\n",
        "    'order_hour_of_day',\n",
        "    'days_since_prior_order',\n",
        "    'is_weekend',\n",
        "    'order_month',\n",
        "    'user_total_items',\n",
        "    'user_avg_days_between',\n",
        "    'user_days_since_last_order',\n",
        "    'product_total_purchases',\n",
        "    'uxp_total_bought',\n",
        "    'uxp_reorder_ratio',\n",
        "    'avg_basket_last_3',\n",
        "    'avg_days_gap_last_3'\n",
        "]\n",
        "\n",
        "X_train_dt = xc_train[dt_features]\n",
        "X_test_dt = xc_test[dt_features]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9db7510a",
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_users = np.random.choice(\n",
        "    xc_train['user_id'].unique(),\n",
        "    size=5000,\n",
        ")\n",
        "\n",
        "dt_x_sample = xc_train[xc_train['user_id'].isin(dt_users)].copy()\n",
        "dt_y_sample = yc_train[xc_train['user_id'].isin(dt_users)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c44263",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_MD = 50\n",
        "best_MSL = 20\n",
        "best_MSS = 20\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=5,\n",
        "    min_samples_leaf=5,\n",
        "    min_samples_split=5,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "final_DT_pipeline = make_pipeline(\n",
        "    preprocessor,\n",
        "    DecisionTreeClassifier(\n",
        "        max_depth=best_MD,\n",
        "        min_samples_leaf=best_MSL,\n",
        "        min_samples_split=best_MSS,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "dt_model.fit(X_train_dt, yc_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "856ac5c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred_DT = dt_model.predict(X_test_dt)\n",
        "\n",
        "print(classification_report(yc_test, y_pred_DT))\n",
        "print(f\"Decision Tree Accuracy: {accuracy_score(yc_test, y_pred_DT):.4f}\")\n",
        "\n",
        "\n",
        "'''Decision Tree Accuracy: 0.8300 with max_depth=30, min_samples_leaf=10, min_samples_split=20'''\n",
        "'''Decision Tree Accuracy: 0.8330 with max_depth=20, min_samples_leaf=10, min_samples_split=10'''\n",
        "'''Decision Tree Accuracy: 0.8331 with max_depth=50, min_samples_leaf=20, min_samples_split=10'''\n",
        "'''Decision Tree Accuracy: 0.8172 with max_depth=5, min_samples_leaf=5, min_samples_split=5  '''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a6a60a",
      "metadata": {},
      "source": [
        "XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d93778d",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install lightgbm \n",
        "!pip install xgboost\n",
        "gb_features = [\n",
        "    'order_dow',\n",
        "    'order_hour_of_day',\n",
        "    'days_since_prior_order',\n",
        "    'is_weekend',\n",
        "    'order_month',\n",
        "    'user_total_items',\n",
        "    'user_avg_days_between',\n",
        "    'user_days_since_last_order',\n",
        "    'product_total_purchases',\n",
        "    'uxp_total_bought',\n",
        "    'uxp_reorder_ratio',\n",
        "    'avg_basket_last_3',\n",
        "    'avg_days_gap_last_3'\n",
        "]\n",
        "\n",
        "gb_users = np.random.choice(\n",
        "    xc_train['user_id'].unique(),\n",
        "    size=5000,\n",
        "    replace=False\n",
        ")\n",
        "\n",
        "X_gb_sample = xc_train[xc_train['user_id'].isin(gb_users)][gb_features]\n",
        "y_gb_sample = yc_train[xc_train['user_id'].isin(gb_users)]\n",
        "\n",
        "X_gb_test = xc_test[gb_features]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3815d94",
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=100,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=(len(y_gb_sample) - y_gb_sample.sum()) / y_gb_sample.sum(),\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_gb_sample, y_gb_sample)\n",
        "\n",
        "y_pred_xgb = xgb_model.predict(X_gb_test)\n",
        "\n",
        "print(classification_report(yc_test, y_pred_xgb))\n",
        "print(f\"XGBoost Accuracy: {accuracy_score(yc_test, y_pred_xgb):.4f}\")\n",
        "\n",
        "'''XGBoost Accuracy: 0.8253 with n_estimators=300, max_depth=6 , learning_rate=0.05'''\n",
        "\n",
        "'''XGBoost Accuracy: 0.8645 with n_estimators=300, max_depth=20 , learning_rate=0.1'''\n",
        "\n",
        "'''XGBoost Accuracy: 0.8637 with n_estimators=300, max_depth=50 , learning_rate=0.1'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c07e6c",
      "metadata": {},
      "source": [
        "LIGHT GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a2f1404",
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_model.fit(X_gb_sample, y_gb_sample)\n",
        "\n",
        "y_pred_lgbm = lgbm_model.predict(X_gb_test)\n",
        "\n",
        "print(classification_report(yc_test, y_pred_lgbm))\n",
        "print(f\"LightGBM Accuracy: {accuracy_score(yc_test, y_pred_lgbm):.4f}\")\n",
        "\n",
        "''''LightGBM Accuracy: 0.8233 with n_estimators=300, max_depth=6 , learning_rate=0.05'''\n",
        "\n",
        "'''LightGBM Accuracy: 0.8255 with n_estimators=300, max_depth=20 , learning_rate=0.1'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fce8c3c",
      "metadata": {},
      "source": [
        "BOUNS AUTO ML "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b25fb29",
      "metadata": {},
      "source": [
        "CLASSIFICATION DONE ✅ TASK 1 ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93a2252",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
